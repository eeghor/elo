{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "import arrow\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from itertools import chain\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\"\n",
    "    pick a specific colums of data frame X for further use within a pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cols):\n",
    "        \n",
    "        self.cols = cols\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        # note that transform_params is expected to have \"cols\", e.g. cols=['card_id', 'city_id', 'state_id']\n",
    "        return X[[w for w in chain(self.cols)]]\n",
    "    \n",
    "class AuthorizationFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\"\n",
    "    have this card even been unauthorised? returns a data frame with card_id as index and a single column called ever_declined\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[['card_id', 'authorized_flag']] \\\n",
    "                    .groupby(['card_id']).sum().iloc[:,0].apply(lambda x: 1 if 'n' in x.lower() else 0).to_frame(name='ever_declined')\n",
    "        \n",
    "class CategoricalFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\"\n",
    "    create binary features from categorical\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return pd.get_dummies(X, prefix={c: f'cat_{c}' for c in X.columns if c != 'card_id'}, \n",
    "                                  columns=[c for c in X.columns if c != 'card_id']).groupby('card_id').sum()\n",
    "\n",
    "\n",
    "class PurchaseDateFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\"\n",
    "    some possibly important features related to the purchase date\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def get_date_features(self, dt):\n",
    "        \n",
    "        \"\"\"\n",
    "        extract potentially useful fetures from a purchase date string\n",
    "        \"\"\"\n",
    "        \n",
    "        DateFeatures = namedtuple('DateFeatures', 'month weekday mall_hrs buss_hrs')\n",
    "        \n",
    "        mall_hours = (10,22)\n",
    "        business_hours = (8,18)\n",
    "        \n",
    "        _dt = arrow.get(dt)\n",
    "        \n",
    "        hr = _dt.hour\n",
    "        \n",
    "        # the features below are per transation while we'll need to switch to per card\n",
    "        out = DateFeatures(month=_dt.month, weekday=_dt.weekday(), \n",
    "                               mall_hrs = 1 if mall_hours[0] <= hr <= mall_hours[1] else 0,\n",
    "                                  buss_hrs = 1 if business_hours[0] <= hr <= business_hours[1] else 0)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        _d = pd.concat([X['card_id'], pd.DataFrame(X['purchase_date'] \\\n",
    "                                                   .apply(lambda _: self.get_date_features(_)).tolist()).set_index(X.index)], axis=1)\n",
    "        \n",
    "        return _d[['card_id', 'month', 'weekday']] \\\n",
    "                    .groupby(['card_id', 'month']) \\\n",
    "                    .count() \\\n",
    "                    .reset_index() \\\n",
    "                    .set_index('card_id') \\\n",
    "                    .pivot(columns='month', values='weekday') \\\n",
    "                    .fillna(0) \\\n",
    "                    .rename(columns=lambda x: '_'.join(['ntrans', arrow.get(str(x), 'M').format('MMM').lower()]))\n",
    "    \n",
    "class Elo:\n",
    "    \n",
    "    def __init__(self, n=10000):\n",
    "        \n",
    "        self.hist_trans = pd.read_csv('data/historical_transactions.csv.gz')\n",
    "        print(f'historical transactions: {len(self.hist_trans):,} rows / {len(self.hist_trans.card_id.unique()):,} cards')\n",
    "        self.new_trans = pd.read_csv('data/new_merchant_transactions.csv.gz')\n",
    "        print(f'new transactions: {len(self.new_trans):,} rows')\n",
    "        self.merchants = pd.read_csv('data/merchants.csv.gz')\n",
    "        print(f'merchants: {len(self.merchants):,} rows')\n",
    "        self.train = pd.read_csv('data/train.csv.gz')\n",
    "        print(f'train: {len(self.train):,} rows')\n",
    "        # categorical columns\n",
    "        self.CAT = {col: col + '_cat' for col in 'authorized_flag city_id category_1 category_2 category_3 merchant_category_id state_id subsector_id'.split()}\n",
    "        # take only a sample of the train set\n",
    "        self.train = self.train.sample(n)\n",
    "        # historical transactions only for the cards in the training set \n",
    "        self.hist_trans = self.hist_trans[self.hist_trans.card_id.isin(self.train.card_id)]\n",
    "        \n",
    "        self.train1 = self.train.join(self.hist_trans.set_index('card_id'), on='card_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "historical transactions: 29,112,361 rows / 325,540 cards\n",
      "new transactions: 1,963,031 rows\n",
      "merchants: 334,696 rows\n",
      "train: 201,917 rows\n",
      "accuracy at training is 15.096625736188283\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    elo = Elo()\n",
    "    \n",
    "    X_train = elo.train1.drop('target', axis=1)\n",
    "    y_train = elo.train['target']   \n",
    "    \n",
    "    estimator = make_pipeline(make_union(AuthorizationFeatures(), \n",
    "                                         make_pipeline(Selector(cols=['card_id', 'city_id', 'state_id']), CategoricalFeatures()), \n",
    "                                         PurchaseDateFeatures()), \n",
    "                              BayesianRidge())\n",
    "    \n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    mse = mean_squared_error(y_train, estimator.predict(X_train))\n",
    "    \n",
    "    print(f'accuracy at training is {mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
